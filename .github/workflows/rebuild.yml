name: Rebuild Site on Data Update

on:
  push:
    branches: [data]
  workflow_dispatch:

permissions:
  contents: write
  pages: write

jobs:
  rebuild:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout main branch
        uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Fetch all files from data branch
        run: |
          # Fetch the data branch
          git fetch origin data
            
          # List all files in data branch
          echo "Files in data branch:"
          git ls-tree -r --name-only origin/data | head -50
          
          # Create data directory
          mkdir -p data_files
          
          # Download all files from data branch
          git ls-tree -r --name-only origin/data | while read file; do
            # Create directory structure
            dir=$(dirname "data_files/$file")
            mkdir -p "$dir"
            # Extract file content
            git show "origin/data:$file" > "data_files/$file" 2>/dev/null || true
          done
          
          echo "Downloaded files:"
          find data_files -type f | head -50

      - name: Convert MD files to JSON
        run: |
          # Create conversion script
          cat > convert.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          
          // Parse YAML frontmatter
          function parseFrontmatter(content) {
            const match = content.match(/^---\n([\s\S]*?)\n---\n([\s\S]*)$/);
            if (!match) return { frontmatter: {}, body: content };
            
            const frontmatter = {};
            match[1].split('\n').forEach(line => {
              const idx = line.indexOf(':');
              if (idx > 0) {
                let key = line.substring(0, idx).trim();
                let value = line.substring(idx + 1).trim();
                
                if (value.startsWith('[') && value.endsWith(']')) {
                  value = value.slice(1, -1).split(',').map(v => v.trim().replace(/^["']|["']$/g, '')).filter(v => v);
                } else if (value === 'true') value = true;
                else if (value === 'false') value = false;
                else if ((value.startsWith('"') && value.endsWith('"')) || (value.startsWith("'") && value.endsWith("'"))) {
                  value = value.slice(1, -1);
                }
                frontmatter[key] = value;
              }
            });
            return { frontmatter, body: match[2] };
          }
          
          // Read all files
          const dataDir = './data_files/data';
          const result = {
            workspaces: [],
            categories: [],
            folders: [],
            notes: [],
            commands: [],
            links: [],
            prompts: [],
            exportedAt: new Date().toISOString(),
            version: '3.0'
          };
          
          // Read metadata if exists
          const metadataPath = path.join(dataDir, 'metadata.json');
          if (fs.existsSync(metadataPath)) {
            try {
              const metadata = JSON.parse(fs.readFileSync(metadataPath, 'utf8'));
              result.workspaces = metadata.workspaces || [];
              result.categories = metadata.categories || [];
              result.folders = metadata.folders || [];
              console.log('Loaded metadata:', result.workspaces.length, 'workspaces,', result.categories.length, 'categories,', result.folders.length, 'folders');
            } catch (e) {
              console.error('Failed to parse metadata:', e);
            }
          }
          
          // If no metadata, create from file structure
          if (result.workspaces.length === 0) {
            console.log('No metadata found, creating structure from files...');
          }
          
          // Process all .md files
          function processDir(dir, workspaceName = '', categoryName = '', folderName = '') {
            if (!fs.existsSync(dir)) return;
            
            const entries = fs.readdirSync(dir, { withFileTypes: true });
            
            for (const entry of entries) {
              const fullPath = path.join(dir, entry.name);
              
              if (entry.isDirectory()) {
                // Determine what level we're at
                const relativePath = path.relative(dataDir, fullPath);
                const parts = relativePath.split(path.sep);
                
                if (parts.length === 1) {
                  // Workspace level
                  processDir(fullPath, entry.name, '', '');
                } else if (parts.length === 2) {
                  // Category level
                  processDir(fullPath, workspaceName, entry.name, '');
                } else if (parts.length === 3) {
                  // Folder level
                  processDir(fullPath, workspaceName, categoryName, entry.name);
                }
              } else if (entry.name.endsWith('.md')) {
                // Process markdown file
                const content = fs.readFileSync(fullPath, 'utf8');
                const { frontmatter, body } = parseFrontmatter(content);
                
                // Add to appropriate array based on path
                const relativePath = path.relative(dataDir, fullPath);
                const parts = relativePath.split(path.sep);
                
                if (parts.length >= 4) {
                  const wsName = parts[0];
                  const catName = parts[1];
                  const fldName = parts[2];
                  
                  // Determine type from category name
                  const type = catName.toLowerCase().includes('command') ? 'commands' :
                              catName.toLowerCase().includes('link') ? 'links' :
                              catName.toLowerCase().includes('prompt') ? 'prompts' : 'notes';
                  
                  const title = frontmatter.title || entry.name.replace('.md', '');
                  
                  if (type === 'notes') {
                    result.notes.push({
                      id: frontmatter.id || Math.random().toString(36).substr(2, 9),
                      folderId: frontmatter.folderId || '',
                      title,
                      content: body.trim(),
                      tags: frontmatter.tags || [],
                      isFavorite: frontmatter.isFavorite || false,
                      createdAt: frontmatter.createdAt || new Date().toISOString(),
                      updatedAt: frontmatter.updatedAt || new Date().toISOString(),
                      type: 'notes'
                    });
                  }
                  // Add other types as needed...
                }
              }
            }
          }
          
          processDir(dataDir);
          
          console.log('Converted:', result.notes.length, 'notes,', result.commands.length, 'commands,', result.links.length, 'links,', result.prompts.length, 'prompts');
          
          // Write result
          fs.writeFileSync('./src/data.json', JSON.stringify(result, null, 2));
          console.log('Written to src/data.json');
          EOF
          
          node convert.js
          
          echo "Data preview:"
          head -50 src/data.json

      - name: Install dependencies
        run: npm ci

      - name: Build site
        run: npm run build

      - name: Deploy to GitHub Pages
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Save build output
          cp dist/index.html /tmp/index.html

          # Switch to gh-pages and update
          git checkout gh-pages || git checkout --orphan gh-pages
          git reset --hard
          cp /tmp/index.html index.html

          git add index.html
          git commit -m "Auto-rebuild: $(date -u +'%Y-%m-%d %H:%M:%S UTC')" || echo "No changes"
          git push origin gh-pages --force
